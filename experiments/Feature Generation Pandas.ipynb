{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from cosmic_rAI.data_prep import (event_df_from_matrices,\n",
    "                                  flatten_event_df)\n",
    "from cosmic_rAI.machine_learning import (split_and_run,\n",
    "                                         get_labels,\n",
    "                                         get_flattened_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(list_of_files):\n",
    "    list_of_dicts = [np.load(filepath).item() for filepath in list_of_files]\n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ('../data/sim_12360_', '../data/sim_12362_')\n",
    "files = []\n",
    "for prefix in prefixes:\n",
    "    for i in range(20):\n",
    "        files.append('{0}{1:02d}.npy'.format(prefix,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = event_df_from_matrices(get_all_data(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use only events in a certain azimuth/zenith band with max charge > 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_band_data = flatten_event_df(data[\n",
    "    data.loc[:, ('dir_MC','zenith')].between(0, .17) & \n",
    "    data.loc[:,('dir_MC','azimuth')].between(0,1) & \n",
    "    (data['charges'].max(axis=1) > 6)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_run(dir_band_data, [x for x in filtered.columns if 'charges' in x], 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use only events with max charges > 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = flatten_event_df(data[\n",
    "        data['charges'].max(axis=1) > 6\n",
    "    ].sample(frac=.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp47w5ck8f\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_task_id': 0, '_model_dir': '/tmp/tmp47w5ck8f', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1273322ef0>, '_is_chief': True, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_task_type': 'worker', '_session_config': None, '_log_step_count_steps': 100, '_master': '', '_tf_random_seed': None, '_service': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp47w5ck8f/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.16419e+07, step = 1\n",
      "INFO:tensorflow:global_step/sec: 27.1791\n",
      "INFO:tensorflow:loss = 228705.0, step = 101 (3.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2833\n",
      "INFO:tensorflow:loss = 176769.0, step = 201 (3.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2202\n",
      "INFO:tensorflow:loss = 112192.0, step = 301 (3.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4362\n",
      "INFO:tensorflow:loss = 69.2348, step = 401 (2.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7939\n",
      "INFO:tensorflow:loss = 68.8962, step = 501 (3.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.8209\n",
      "INFO:tensorflow:loss = 69.4068, step = 601 (3.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8753\n",
      "INFO:tensorflow:loss = 69.1454, step = 701 (3.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6401\n",
      "INFO:tensorflow:loss = 69.2378, step = 801 (3.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.8677\n",
      "INFO:tensorflow:loss = 68.7409, step = 901 (3.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.208\n",
      "INFO:tensorflow:loss = 69.7729, step = 1001 (3.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1203\n",
      "INFO:tensorflow:loss = 68.9129, step = 1101 (3.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7808\n",
      "INFO:tensorflow:loss = 70.1502, step = 1201 (3.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8203\n",
      "INFO:tensorflow:loss = 69.02, step = 1301 (3.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3895\n",
      "INFO:tensorflow:loss = 69.2506, step = 1401 (3.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3163\n",
      "INFO:tensorflow:loss = 68.7999, step = 1501 (3.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9127\n",
      "INFO:tensorflow:loss = 69.2468, step = 1601 (3.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.8288\n",
      "INFO:tensorflow:loss = 69.5701, step = 1701 (3.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0583\n",
      "INFO:tensorflow:loss = 68.7022, step = 1801 (3.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2632\n",
      "INFO:tensorflow:loss = 68.809, step = 1901 (3.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6693\n",
      "INFO:tensorflow:loss = 69.6895, step = 2001 (3.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.49\n",
      "INFO:tensorflow:loss = 69.6705, step = 2101 (3.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6427\n",
      "INFO:tensorflow:loss = 68.2844, step = 2201 (3.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2188\n",
      "INFO:tensorflow:loss = 69.464, step = 2301 (3.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7561\n",
      "INFO:tensorflow:loss = 68.9089, step = 2401 (3.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2578\n",
      "INFO:tensorflow:loss = 69.694, step = 2501 (3.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9462\n",
      "INFO:tensorflow:loss = 68.1586, step = 2601 (2.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6221\n",
      "INFO:tensorflow:loss = 68.0284, step = 2701 (2.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0172\n",
      "INFO:tensorflow:loss = 69.8297, step = 2801 (7.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.231\n",
      "INFO:tensorflow:loss = 68.5394, step = 2901 (3.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8571\n",
      "INFO:tensorflow:loss = 69.6053, step = 3001 (3.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6393\n",
      "INFO:tensorflow:loss = 68.5512, step = 3101 (2.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4202\n",
      "INFO:tensorflow:loss = 69.6132, step = 3201 (2.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6878\n",
      "INFO:tensorflow:loss = 68.8975, step = 3301 (2.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6925\n",
      "INFO:tensorflow:loss = 68.7918, step = 3401 (2.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9377\n",
      "INFO:tensorflow:loss = 69.4718, step = 3501 (2.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4655\n",
      "INFO:tensorflow:loss = 69.71, step = 3601 (2.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.0771\n",
      "INFO:tensorflow:loss = 69.4696, step = 3701 (2.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.1394\n",
      "INFO:tensorflow:loss = 67.6616, step = 3801 (2.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2835\n",
      "INFO:tensorflow:loss = 67.7549, step = 3901 (2.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4163\n",
      "INFO:tensorflow:loss = 69.6171, step = 4001 (2.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4537\n",
      "INFO:tensorflow:loss = 68.8922, step = 4101 (2.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3891\n",
      "INFO:tensorflow:loss = 69.2553, step = 4201 (3.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4731\n",
      "INFO:tensorflow:loss = 69.1346, step = 4301 (3.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5491\n",
      "INFO:tensorflow:loss = 69.9505, step = 4401 (3.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1755\n",
      "INFO:tensorflow:loss = 69.0172, step = 4501 (3.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.452\n",
      "INFO:tensorflow:loss = 69.8413, step = 4601 (3.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5928\n",
      "INFO:tensorflow:loss = 68.7796, step = 4701 (3.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2899\n",
      "INFO:tensorflow:loss = 68.9002, step = 4801 (3.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5333\n",
      "INFO:tensorflow:loss = 68.4314, step = 4901 (3.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.992\n",
      "INFO:tensorflow:loss = 68.3365, step = 5001 (3.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8117\n",
      "INFO:tensorflow:loss = 68.1259, step = 5101 (3.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0778\n",
      "INFO:tensorflow:loss = 69.5875, step = 5201 (3.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9458\n",
      "INFO:tensorflow:loss = 68.5655, step = 5301 (3.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9191\n",
      "INFO:tensorflow:loss = 68.9045, step = 5401 (2.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3937\n",
      "INFO:tensorflow:loss = 68.2135, step = 5501 (3.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4746\n",
      "INFO:tensorflow:loss = 68.7912, step = 5601 (7.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4506\n",
      "INFO:tensorflow:loss = 70.382, step = 5701 (3.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6253\n",
      "INFO:tensorflow:loss = 69.0189, step = 5801 (3.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.8882\n",
      "INFO:tensorflow:loss = 69.0146, step = 5901 (3.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7871\n",
      "INFO:tensorflow:loss = 68.8956, step = 6001 (3.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4139\n",
      "INFO:tensorflow:loss = 69.2557, step = 6101 (3.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3601\n",
      "INFO:tensorflow:loss = 69.6126, step = 6201 (3.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2146\n",
      "INFO:tensorflow:loss = 69.0147, step = 6301 (2.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5466\n",
      "INFO:tensorflow:loss = 68.4283, step = 6401 (3.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.7286\n",
      "INFO:tensorflow:loss = 69.4906, step = 6501 (3.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1666\n",
      "INFO:tensorflow:loss = 68.5529, step = 6601 (3.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8937\n",
      "INFO:tensorflow:loss = 68.1667, step = 6701 (3.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3676\n",
      "INFO:tensorflow:loss = 69.2526, step = 6801 (3.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8914\n",
      "INFO:tensorflow:loss = 69.614, step = 6901 (3.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6911\n",
      "INFO:tensorflow:loss = 70.0693, step = 7001 (3.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.579\n",
      "INFO:tensorflow:loss = 68.8979, step = 7101 (3.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.505\n",
      "INFO:tensorflow:loss = 69.8464, step = 7201 (3.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2223\n",
      "INFO:tensorflow:loss = 68.7862, step = 7301 (3.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9773\n",
      "INFO:tensorflow:loss = 69.3642, step = 7401 (3.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2649\n",
      "INFO:tensorflow:loss = 68.6709, step = 7501 (3.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3142\n",
      "INFO:tensorflow:loss = 69.135, step = 7601 (3.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 70.2923, step = 7701 (3.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6678\n",
      "INFO:tensorflow:loss = 68.9087, step = 7801 (3.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4576\n",
      "INFO:tensorflow:loss = 68.6842, step = 7901 (3.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0586\n",
      "INFO:tensorflow:loss = 68.7926, step = 8001 (3.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.1867\n",
      "INFO:tensorflow:loss = 69.8216, step = 8101 (2.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.112\n",
      "INFO:tensorflow:loss = 69.2488, step = 8201 (2.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1328\n",
      "INFO:tensorflow:loss = 69.1348, step = 8301 (3.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9765\n",
      "INFO:tensorflow:loss = 69.3656, step = 8401 (6.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9118\n",
      "INFO:tensorflow:loss = 69.1348, step = 8501 (2.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2948\n",
      "INFO:tensorflow:loss = 69.0201, step = 8601 (2.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8962\n",
      "INFO:tensorflow:loss = 69.8422, step = 8701 (3.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1336\n",
      "INFO:tensorflow:loss = 69.1346, step = 8801 (3.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8421\n",
      "INFO:tensorflow:loss = 68.4184, step = 8901 (3.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0867\n",
      "INFO:tensorflow:loss = 68.5461, step = 9001 (3.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7092\n",
      "INFO:tensorflow:loss = 68.6714, step = 9101 (3.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5037\n",
      "INFO:tensorflow:loss = 70.2885, step = 9201 (2.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8871\n",
      "INFO:tensorflow:loss = 69.2531, step = 9301 (2.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0096\n",
      "INFO:tensorflow:loss = 69.2524, step = 9401 (3.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0782\n",
      "INFO:tensorflow:loss = 69.3704, step = 9501 (2.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.1135\n",
      "INFO:tensorflow:loss = 69.3703, step = 9601 (3.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0631\n",
      "INFO:tensorflow:loss = 69.4794, step = 9701 (2.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7175\n",
      "INFO:tensorflow:loss = 69.4831, step = 9801 (3.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0189\n",
      "INFO:tensorflow:loss = 67.9599, step = 9901 (3.331 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmp47w5ck8f/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 69.4886.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-14-17:47:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp47w5ck8f/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-14-17:47:42\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.528473, accuracy_baseline = 0.528473, auc = 0.5, auc_precision_recall = 0.735764, average_loss = 0.691527, global_step = 10000, label/mean = 0.471527, loss = 68.9714, prediction/mean = 0.470577\n",
      "\n",
      "Test set accuracy: 0.528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_and_run(full_flat, ['core_MC_x', 'core_MC_y', 'dir_MC_azimuth', 'dir_MC_zenith', 'energy_0'] + [x for x in filtered.columns if 'charges' in x], 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use events within a certain energy range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = flatten_event_df(data[\n",
    "        (data.loc[:,('energy',0)] < 1000000)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphfaudm36\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_task_id': 0, '_model_dir': '/tmp/tmphfaudm36', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1271ca6358>, '_is_chief': True, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_task_type': 'worker', '_session_config': None, '_log_step_count_steps': 100, '_master': '', '_tf_random_seed': None, '_service': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmphfaudm36/model.ckpt.\n",
      "INFO:tensorflow:loss = 103.03, step = 1\n",
      "INFO:tensorflow:global_step/sec: 26.6577\n",
      "INFO:tensorflow:loss = 24.2065, step = 101 (3.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5293\n",
      "INFO:tensorflow:loss = 15.8193, step = 201 (3.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.259\n",
      "INFO:tensorflow:loss = 8.58105, step = 301 (3.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0512\n",
      "INFO:tensorflow:loss = 4.28838, step = 401 (3.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1091\n",
      "INFO:tensorflow:loss = 4.74707, step = 501 (3.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1044\n",
      "INFO:tensorflow:loss = 2.09291, step = 601 (3.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7732\n",
      "INFO:tensorflow:loss = 2.23399, step = 701 (3.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9984\n",
      "INFO:tensorflow:loss = 1.7718, step = 801 (3.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0326\n",
      "INFO:tensorflow:loss = 1.03464, step = 901 (3.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5413\n",
      "INFO:tensorflow:loss = 0.722726, step = 1001 (3.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.947\n",
      "INFO:tensorflow:loss = 0.300279, step = 1101 (3.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6302\n",
      "INFO:tensorflow:loss = 0.167217, step = 1201 (3.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.642\n",
      "INFO:tensorflow:loss = 0.514886, step = 1301 (3.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6842\n",
      "INFO:tensorflow:loss = 0.122646, step = 1401 (3.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3072\n",
      "INFO:tensorflow:loss = 0.280681, step = 1501 (3.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9288\n",
      "INFO:tensorflow:loss = 0.203011, step = 1601 (3.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9007\n",
      "INFO:tensorflow:loss = 0.219462, step = 1701 (3.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.782\n",
      "INFO:tensorflow:loss = 0.278939, step = 1801 (2.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2677\n",
      "INFO:tensorflow:loss = 0.271558, step = 1901 (2.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2477\n",
      "INFO:tensorflow:loss = 0.122908, step = 2001 (3.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3609\n",
      "INFO:tensorflow:loss = 0.0957199, step = 2101 (3.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.4705\n",
      "INFO:tensorflow:loss = 0.222618, step = 2201 (2.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7955\n",
      "INFO:tensorflow:loss = 0.125781, step = 2301 (3.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.632\n",
      "INFO:tensorflow:loss = 0.0420221, step = 2401 (3.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5975\n",
      "INFO:tensorflow:loss = 0.0720373, step = 2501 (3.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5838\n",
      "INFO:tensorflow:loss = 0.0948994, step = 2601 (3.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1468\n",
      "INFO:tensorflow:loss = 0.0833806, step = 2701 (3.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0863\n",
      "INFO:tensorflow:loss = 0.0406082, step = 2801 (3.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0463\n",
      "INFO:tensorflow:loss = 0.0697836, step = 2901 (3.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4335\n",
      "INFO:tensorflow:loss = 0.0192559, step = 3001 (3.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0219\n",
      "INFO:tensorflow:loss = 0.0667348, step = 3101 (3.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6383\n",
      "INFO:tensorflow:loss = 0.0782971, step = 3201 (3.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8204\n",
      "INFO:tensorflow:loss = 0.0776099, step = 3301 (3.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5858\n",
      "INFO:tensorflow:loss = 0.0200877, step = 3401 (3.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0545\n",
      "INFO:tensorflow:loss = 0.0877131, step = 3501 (3.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.468\n",
      "INFO:tensorflow:loss = 0.0466043, step = 3601 (3.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9036\n",
      "INFO:tensorflow:loss = 0.0643244, step = 3701 (3.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.586\n",
      "INFO:tensorflow:loss = 0.0134681, step = 3801 (3.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1849\n",
      "INFO:tensorflow:loss = 0.0197614, step = 3901 (3.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7183\n",
      "INFO:tensorflow:loss = 0.0246567, step = 4001 (3.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1976\n",
      "INFO:tensorflow:loss = 0.0266028, step = 4101 (3.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3985\n",
      "INFO:tensorflow:loss = 0.0268317, step = 4201 (3.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7303\n",
      "INFO:tensorflow:loss = 0.0219699, step = 4301 (3.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.069\n",
      "INFO:tensorflow:loss = 0.0550997, step = 4401 (3.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5593\n",
      "INFO:tensorflow:loss = 0.0261251, step = 4501 (2.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5253\n",
      "INFO:tensorflow:loss = 0.0334137, step = 4601 (3.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5646\n",
      "INFO:tensorflow:loss = 0.014456, step = 4701 (3.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5713\n",
      "INFO:tensorflow:loss = 0.0436808, step = 4801 (3.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6757\n",
      "INFO:tensorflow:loss = 0.0201245, step = 4901 (2.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6559\n",
      "INFO:tensorflow:loss = 0.0158109, step = 5001 (3.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4889\n",
      "INFO:tensorflow:loss = 0.0250368, step = 5101 (3.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1943\n",
      "INFO:tensorflow:loss = 0.0162112, step = 5201 (2.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6624\n",
      "INFO:tensorflow:loss = 0.00864097, step = 5301 (2.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1559\n",
      "INFO:tensorflow:loss = 0.0470565, step = 5401 (3.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4993\n",
      "INFO:tensorflow:loss = 0.0324956, step = 5501 (3.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0815\n",
      "INFO:tensorflow:loss = 0.0184266, step = 5601 (3.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6478\n",
      "INFO:tensorflow:loss = 0.0237895, step = 5701 (3.161 sec)\n"
     ]
    }
   ],
   "source": [
    "split_and_run(filtered, [x for x in filtered.columns if 'charges' in x], 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use only events within certain energy range, azimuth/zenith band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = flatten_event_df(data[\n",
    "        (data.loc[:,('energy',0)] < 1000000) &\n",
    "        data.loc[:, ('dir_MC','zenith')].between(0, .17) &\n",
    "        data.loc[:,('dir_MC','azimuth')].between(0,1) &\n",
    "        (data['charges'].max(axis=1) > 6)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphfaudm36\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_task_id': 0, '_model_dir': '/tmp/tmphfaudm36', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1271ca6358>, '_is_chief': True, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_task_type': 'worker', '_session_config': None, '_log_step_count_steps': 100, '_master': '', '_tf_random_seed': None, '_service': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmphfaudm36/model.ckpt.\n",
      "INFO:tensorflow:loss = 103.03, step = 1\n",
      "INFO:tensorflow:global_step/sec: 26.6577\n",
      "INFO:tensorflow:loss = 24.2065, step = 101 (3.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5293\n",
      "INFO:tensorflow:loss = 15.8193, step = 201 (3.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.259\n",
      "INFO:tensorflow:loss = 8.58105, step = 301 (3.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0512\n",
      "INFO:tensorflow:loss = 4.28838, step = 401 (3.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1091\n",
      "INFO:tensorflow:loss = 4.74707, step = 501 (3.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1044\n",
      "INFO:tensorflow:loss = 2.09291, step = 601 (3.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7732\n",
      "INFO:tensorflow:loss = 2.23399, step = 701 (3.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9984\n",
      "INFO:tensorflow:loss = 1.7718, step = 801 (3.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0326\n",
      "INFO:tensorflow:loss = 1.03464, step = 901 (3.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5413\n",
      "INFO:tensorflow:loss = 0.722726, step = 1001 (3.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.947\n",
      "INFO:tensorflow:loss = 0.300279, step = 1101 (3.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6302\n",
      "INFO:tensorflow:loss = 0.167217, step = 1201 (3.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.642\n",
      "INFO:tensorflow:loss = 0.514886, step = 1301 (3.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6842\n",
      "INFO:tensorflow:loss = 0.122646, step = 1401 (3.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3072\n",
      "INFO:tensorflow:loss = 0.280681, step = 1501 (3.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9288\n",
      "INFO:tensorflow:loss = 0.203011, step = 1601 (3.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9007\n",
      "INFO:tensorflow:loss = 0.219462, step = 1701 (3.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.782\n",
      "INFO:tensorflow:loss = 0.278939, step = 1801 (2.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2677\n",
      "INFO:tensorflow:loss = 0.271558, step = 1901 (2.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2477\n",
      "INFO:tensorflow:loss = 0.122908, step = 2001 (3.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3609\n",
      "INFO:tensorflow:loss = 0.0957199, step = 2101 (3.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.4705\n",
      "INFO:tensorflow:loss = 0.222618, step = 2201 (2.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7955\n",
      "INFO:tensorflow:loss = 0.125781, step = 2301 (3.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.632\n",
      "INFO:tensorflow:loss = 0.0420221, step = 2401 (3.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5975\n",
      "INFO:tensorflow:loss = 0.0720373, step = 2501 (3.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5838\n",
      "INFO:tensorflow:loss = 0.0948994, step = 2601 (3.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1468\n",
      "INFO:tensorflow:loss = 0.0833806, step = 2701 (3.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0863\n",
      "INFO:tensorflow:loss = 0.0406082, step = 2801 (3.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0463\n",
      "INFO:tensorflow:loss = 0.0697836, step = 2901 (3.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4335\n",
      "INFO:tensorflow:loss = 0.0192559, step = 3001 (3.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0219\n",
      "INFO:tensorflow:loss = 0.0667348, step = 3101 (3.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6383\n",
      "INFO:tensorflow:loss = 0.0782971, step = 3201 (3.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8204\n",
      "INFO:tensorflow:loss = 0.0776099, step = 3301 (3.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5858\n",
      "INFO:tensorflow:loss = 0.0200877, step = 3401 (3.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0545\n",
      "INFO:tensorflow:loss = 0.0877131, step = 3501 (3.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.468\n",
      "INFO:tensorflow:loss = 0.0466043, step = 3601 (3.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9036\n",
      "INFO:tensorflow:loss = 0.0643244, step = 3701 (3.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.586\n",
      "INFO:tensorflow:loss = 0.0134681, step = 3801 (3.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1849\n",
      "INFO:tensorflow:loss = 0.0197614, step = 3901 (3.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7183\n",
      "INFO:tensorflow:loss = 0.0246567, step = 4001 (3.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1976\n",
      "INFO:tensorflow:loss = 0.0266028, step = 4101 (3.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3985\n",
      "INFO:tensorflow:loss = 0.0268317, step = 4201 (3.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7303\n",
      "INFO:tensorflow:loss = 0.0219699, step = 4301 (3.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.069\n",
      "INFO:tensorflow:loss = 0.0550997, step = 4401 (3.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5593\n",
      "INFO:tensorflow:loss = 0.0261251, step = 4501 (2.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5253\n",
      "INFO:tensorflow:loss = 0.0334137, step = 4601 (3.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5646\n",
      "INFO:tensorflow:loss = 0.014456, step = 4701 (3.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5713\n",
      "INFO:tensorflow:loss = 0.0436808, step = 4801 (3.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.6757\n",
      "INFO:tensorflow:loss = 0.0201245, step = 4901 (2.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6559\n",
      "INFO:tensorflow:loss = 0.0158109, step = 5001 (3.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4889\n",
      "INFO:tensorflow:loss = 0.0250368, step = 5101 (3.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1943\n",
      "INFO:tensorflow:loss = 0.0162112, step = 5201 (2.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6624\n",
      "INFO:tensorflow:loss = 0.00864097, step = 5301 (2.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1559\n",
      "INFO:tensorflow:loss = 0.0470565, step = 5401 (3.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4993\n",
      "INFO:tensorflow:loss = 0.0324956, step = 5501 (3.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0815\n",
      "INFO:tensorflow:loss = 0.0184266, step = 5601 (3.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6478\n",
      "INFO:tensorflow:loss = 0.0237895, step = 5701 (3.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0275\n",
      "INFO:tensorflow:loss = 0.00593062, step = 5801 (3.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.408\n",
      "INFO:tensorflow:loss = 0.0181239, step = 5901 (2.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0007\n",
      "INFO:tensorflow:loss = 0.0156486, step = 6001 (3.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4604\n",
      "INFO:tensorflow:loss = 0.0171362, step = 6101 (3.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2025\n",
      "INFO:tensorflow:loss = 0.0143485, step = 6201 (2.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.136\n",
      "INFO:tensorflow:loss = 0.0107353, step = 6301 (2.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9543\n",
      "INFO:tensorflow:loss = 0.0135365, step = 6401 (3.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.598\n",
      "INFO:tensorflow:loss = 0.00781716, step = 6501 (2.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6592\n",
      "INFO:tensorflow:loss = 0.00973933, step = 6601 (3.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8455\n",
      "INFO:tensorflow:loss = 0.0156821, step = 6701 (3.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7701\n",
      "INFO:tensorflow:loss = 0.0335691, step = 6801 (3.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6364\n",
      "INFO:tensorflow:loss = 0.0067822, step = 6901 (3.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6885\n",
      "INFO:tensorflow:loss = 0.012622, step = 7001 (3.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.8063\n",
      "INFO:tensorflow:loss = 0.0318297, step = 7101 (3.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.79\n",
      "INFO:tensorflow:loss = 0.00852156, step = 7201 (3.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6311\n",
      "INFO:tensorflow:loss = 0.0173538, step = 7301 (3.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.9635\n",
      "INFO:tensorflow:loss = 0.0149578, step = 7401 (2.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7639\n",
      "INFO:tensorflow:loss = 0.0053263, step = 7501 (2.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0169283, step = 7601 (3.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0982\n",
      "INFO:tensorflow:loss = 0.0171686, step = 7701 (2.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4345\n",
      "INFO:tensorflow:loss = 0.0180109, step = 7801 (3.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1294\n",
      "INFO:tensorflow:loss = 0.00812574, step = 7901 (3.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6994\n",
      "INFO:tensorflow:loss = 0.0133146, step = 8001 (3.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7616\n",
      "INFO:tensorflow:loss = 0.012305, step = 8101 (3.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3911\n",
      "INFO:tensorflow:loss = 0.0245767, step = 8201 (3.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9971\n",
      "INFO:tensorflow:loss = 0.00682523, step = 8301 (3.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4645\n",
      "INFO:tensorflow:loss = 0.00576752, step = 8401 (3.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4686\n",
      "INFO:tensorflow:loss = 0.00650614, step = 8501 (3.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2591\n",
      "INFO:tensorflow:loss = 0.0142323, step = 8601 (3.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5075\n",
      "INFO:tensorflow:loss = 0.00634546, step = 8701 (2.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3348\n",
      "INFO:tensorflow:loss = 0.00664425, step = 8801 (3.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4292\n",
      "INFO:tensorflow:loss = 0.00604661, step = 8901 (3.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4251\n",
      "INFO:tensorflow:loss = 0.00915682, step = 9001 (3.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4618\n",
      "INFO:tensorflow:loss = 0.00875576, step = 9101 (3.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.1564\n",
      "INFO:tensorflow:loss = 0.0155347, step = 9201 (3.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1874\n",
      "INFO:tensorflow:loss = 0.00490525, step = 9301 (3.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8973\n",
      "INFO:tensorflow:loss = 0.00667775, step = 9401 (3.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.563\n",
      "INFO:tensorflow:loss = 0.00647084, step = 9501 (3.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8943\n",
      "INFO:tensorflow:loss = 0.00673561, step = 9601 (3.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2944\n",
      "INFO:tensorflow:loss = 0.0125989, step = 9701 (3.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.164\n",
      "INFO:tensorflow:loss = 0.0100268, step = 9801 (3.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.9571\n",
      "INFO:tensorflow:loss = 0.00734335, step = 9901 (3.339 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmphfaudm36/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00628646.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-14-17:20:20\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphfaudm36/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-14-17:20:21\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.666667, accuracy_baseline = 0.738095, auc = 0.517595, auc_precision_recall = 0.345924, average_loss = 7.29688, global_step = 10000, label/mean = 0.261905, loss = 612.938, prediction/mean = 0.197698\n",
      "\n",
      "Test set accuracy: 0.667\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        charges_0161  charges_0162  charges_0163  charges_0164  charges_0261  \\\n",
       " 172910      1.458593           0.0      1.830331           0.0      0.000000   \n",
       " 12884       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 172898      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 115367      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 2505        0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 122420      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 152579      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 44842       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 210814      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 258792      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 210790      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 141094      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 166758      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 547535      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 547964      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 50618       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 6889        0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 128351      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 244686      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 198148      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 56849       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 78775       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 78769       0.000000           0.0      0.000000           0.0      0.963666   \n",
       " 260779      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 352530      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 312205      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 344459      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 78772       0.000000           0.0      0.000000           0.0      2.549040   \n",
       " 128364      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 166757      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " ...              ...           ...           ...           ...           ...   \n",
       " 13886       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 152591      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 13910       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 141076      0.000000           0.0      0.000000           0.0      1.804696   \n",
       " 402313      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 213361      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 310665      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 547525      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 141087      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 402307      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 12887       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 402306      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 141082      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 19276       0.000000           0.0      0.000000           0.0      0.469781   \n",
       " 623224      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 176924      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 547968      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 152581      0.000000           0.0      0.000000           0.0      1.548577   \n",
       " 412681      0.000000           0.0      0.000000           0.0      0.403621   \n",
       " 150742      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 78764       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 13902       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 479091      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 232225      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 489999      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 150752      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 19255       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 344463      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 412679      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 25961       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " \n",
       "         charges_0262  charges_0263  charges_0264  charges_0361  charges_0362  \\\n",
       " 172910     94.097794      0.000000     33.367554      0.644890      0.000000   \n",
       " 12884       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 172898      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 115367      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 2505        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 122420      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 152579      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 44842       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 210814      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 258792      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 210790      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 141094      0.000000      0.000000      0.000000      0.646523      0.000000   \n",
       " 166758      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 547535      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 547964      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 50618       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 6889        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 128351      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 244686      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 198148      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 56849       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 78775       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 78769       0.000000      0.266321      0.000000      0.000000     71.269188   \n",
       " 260779      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 352530      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 312205      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 344459      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 78772       0.000000      0.872361      0.000000      0.000000     76.597527   \n",
       " 128364      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 166757      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " ...              ...           ...           ...           ...           ...   \n",
       " 13886       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 152591      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 13910       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 141076      0.000000      0.477152      0.000000      5.781737      0.000000   \n",
       " 402313      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 213361      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 310665      0.000000      0.000000      0.000000      1.998041      0.000000   \n",
       " 547525      0.000000      0.000000      0.000000      1.294725      0.000000   \n",
       " 141087      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 402307      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 12887       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 402306      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 141082      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 19276       0.000000      0.882349      0.000000     11.447412      0.000000   \n",
       " 623224      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 176924      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 547968      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 152581      0.000000      3.476449      0.000000      0.848583      0.000000   \n",
       " 412681      0.000000      0.253502      0.000000      1.819502      0.000000   \n",
       " 150742      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 78764       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 13902       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 479091      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 232225      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 489999      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 150752      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 19255       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 344463      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 412679      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " 25961       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       " \n",
       "             ...        composition_0   core_MC_x   core_MC_y  core_reco_x  \\\n",
       " 172910      ...                PPlus -156.431837 -484.019324  -160.143496   \n",
       " 12884       ...                PPlus   91.750512 -189.411257   103.676000   \n",
       " 172898      ...                PPlus -210.541941  -28.126039  -231.810591   \n",
       " 115367      ...                PPlus -213.565168    0.849460  -217.767485   \n",
       " 2505        ...                PPlus -167.032383 -245.040323  -196.548235   \n",
       " 122420      ...                PPlus  -62.750466 -260.479627   -50.249442   \n",
       " 152579      ...                PPlus -440.434428 -126.796045  -448.867226   \n",
       " 44842       ...                PPlus   36.374986  302.868780    11.213287   \n",
       " 210814      ...                PPlus -360.775047  145.436574  -325.234999   \n",
       " 258792      ...                PPlus -127.971310   24.794400  -129.816937   \n",
       " 210790      ...                PPlus -281.613323  282.768593  -266.101739   \n",
       " 141094      ...                PPlus  117.478868 -377.675171   132.281212   \n",
       " 166758      ...                PPlus   60.357352  170.247344    65.862774   \n",
       " 547535      ...          Fe56Nucleus  198.860596  -67.198877   174.316669   \n",
       " 547964      ...          Fe56Nucleus  158.186585 -112.317588   154.320929   \n",
       " 50618       ...                PPlus -333.711155  113.520989  -333.444134   \n",
       " 6889        ...                PPlus  173.994810 -339.113698   107.150299   \n",
       " 128351      ...                PPlus  258.495367  172.957570   207.555656   \n",
       " 244686      ...                PPlus  -47.100144  195.871723   -22.088547   \n",
       " 198148      ...                PPlus  107.039229 -340.777924    92.235156   \n",
       " 56849       ...                PPlus  -77.449190  -25.965773   -69.675928   \n",
       " 78775       ...                PPlus  286.359239  205.436862   285.476007   \n",
       " 78769       ...                PPlus  -24.644884 -446.367987   -16.194456   \n",
       " 260779      ...                PPlus  223.609088 -242.558202   251.283409   \n",
       " 352530      ...          Fe56Nucleus -250.147162 -212.547662  -225.492078   \n",
       " 312205      ...                PPlus -212.492706  272.496352  -221.359803   \n",
       " 344459      ...          Fe56Nucleus -272.230776   28.438485     0.000000   \n",
       " 78772       ...                PPlus  -12.521816 -478.658692   -20.666027   \n",
       " 128364      ...                PPlus  129.722389  158.305219   131.174762   \n",
       " 166757      ...                PPlus -392.599557 -313.218680  -385.412923   \n",
       " ...         ...                  ...         ...         ...          ...   \n",
       " 13886       ...                PPlus -252.618518 -245.955127  -241.641322   \n",
       " 152591      ...                PPlus -280.535203  193.040560  -256.659888   \n",
       " 13910       ...                PPlus -284.379793  142.572613  -267.279370   \n",
       " 141076      ...                PPlus   14.453218 -405.658344   -11.338948   \n",
       " 402313      ...          Fe56Nucleus   -1.030248  193.158120    13.841898   \n",
       " 213361      ...                PPlus   24.957684  -71.056420    30.847561   \n",
       " 310665      ...                PPlus  131.302575 -423.170727   118.064348   \n",
       " 547525      ...          Fe56Nucleus   57.397830 -374.809365    68.147292   \n",
       " 141087      ...                PPlus  184.546546   -8.387877   152.574005   \n",
       " 402307      ...          Fe56Nucleus  289.831524 -199.446085   262.505020   \n",
       " 12887       ...                PPlus   74.412463 -323.847423    78.588590   \n",
       " 402306      ...          Fe56Nucleus  390.838379 -245.284516   368.649756   \n",
       " 141082      ...                PPlus -322.971654  240.623692  -321.635729   \n",
       " 19276       ...                PPlus   23.372698 -457.316940    15.283466   \n",
       " 623224      ...          Fe56Nucleus -273.543453  260.161787  -266.691393   \n",
       " 176924      ...                PPlus   76.318760 -159.955478    45.360723   \n",
       " 547968      ...          Fe56Nucleus -210.968749  331.378690  -210.491298   \n",
       " 152581      ...                PPlus -127.415283 -400.808092   -88.064126   \n",
       " 412681      ...          Fe56Nucleus   12.391643 -375.451307     2.848162   \n",
       " 150742      ...                PPlus  281.660251  313.208159   282.959161   \n",
       " 78764       ...                PPlus -414.698344  178.102240  -397.467939   \n",
       " 13902       ...                PPlus  123.673396 -307.960625   122.676812   \n",
       " 479091      ...          Fe56Nucleus  364.399418 -286.876706   351.738132   \n",
       " 232225      ...                PPlus -303.024933 -138.631818  -351.210668   \n",
       " 489999      ...          Fe56Nucleus  -68.556111 -176.056239   -55.239280   \n",
       " 150752      ...                PPlus -284.130753 -118.338411  -295.846264   \n",
       " 19255       ...                PPlus -158.384610  -79.120465  -159.550868   \n",
       " 344463      ...          Fe56Nucleus  118.556524  -51.341027   110.342313   \n",
       " 412679      ...          Fe56Nucleus   71.930207 -147.352878    33.041474   \n",
       " 25961       ...                PPlus  283.582669 -233.188699   291.797328   \n",
       " \n",
       "         core_reco_y  dir_MC_azimuth  dir_MC_zenith  dir_reco_azimuth  \\\n",
       " 172910  -468.791934        0.284481       0.090934          0.300313   \n",
       " 12884   -181.281188        0.550200       0.154423          0.541741   \n",
       " 172898   -52.899935        0.284481       0.090934          0.341047   \n",
       " 115367     5.797748        0.510620       0.098733          0.521113   \n",
       " 2505    -257.573416        0.432687       0.013495          0.520224   \n",
       " 122420  -271.632416        0.328141       0.116073          0.356294   \n",
       " 152579  -116.518979        0.527380       0.075960          0.529457   \n",
       " 44842    288.756338        0.581050       0.048873          0.590392   \n",
       " 210814    76.407486        0.629870       0.136019          0.615863   \n",
       " 258792    20.627113        0.738279       0.020523          0.748744   \n",
       " 210790   275.352495        0.238186       0.062210          0.167249   \n",
       " 141094  -381.895072        0.406916       0.061067          0.405626   \n",
       " 166758   186.232988        0.717072       0.161655          0.670616   \n",
       " 547535   -70.973834        0.509197       0.074494          0.548898   \n",
       " 547964   -97.705837        0.071561       0.084275          0.082312   \n",
       " 50618    107.136896        0.669990       0.075197          0.692855   \n",
       " 6889    -319.632766        0.304899       0.141751          0.370575   \n",
       " 128351   182.780002        0.312548       0.134542          0.337460   \n",
       " 244686   222.276101        0.398399       0.130374          0.382899   \n",
       " 198148  -325.104782        0.706118       0.119155          0.702753   \n",
       " 56849    -28.148018        0.272181       0.082175          0.260994   \n",
       " 78775    216.349050        0.526536       0.147221          0.497798   \n",
       " 78769   -437.238584        0.526536       0.147221          0.540446   \n",
       " 260779  -214.277072        0.426446       0.095457          0.380362   \n",
       " 352530  -234.827702        0.507170       0.075400          0.515939   \n",
       " 312205   265.672465        0.275759       0.127317          0.293370   \n",
       " 344459     0.000000        0.557494       0.150728          0.000000   \n",
       " 78772   -456.824255        0.526536       0.147221          0.527698   \n",
       " 128364   152.732198        0.161964       0.075270          0.195324   \n",
       " 166757  -311.953207        0.717072       0.161655          0.720884   \n",
       " ...             ...             ...            ...               ...   \n",
       " 13886   -240.271716        0.247591       0.114001          0.212056   \n",
       " 152591   203.271299        0.527380       0.075960          0.515423   \n",
       " 13910    137.196516        0.247591       0.114001          0.232871   \n",
       " 141076  -413.966476        0.406916       0.061067          0.416971   \n",
       " 402313   191.611704        0.284076       0.075420          0.232169   \n",
       " 213361   -65.620211        0.763894       0.061985          0.715616   \n",
       " 310665  -421.982602        0.626379       0.089807          0.643369   \n",
       " 547525  -367.129828        0.509197       0.074494          0.516171   \n",
       " 141087   -52.058608        0.406916       0.061067          0.395174   \n",
       " 402307  -198.476607        0.284076       0.075420          0.267485   \n",
       " 12887   -317.298314        0.550200       0.154423          0.539920   \n",
       " 402306  -250.026724        0.284076       0.075420          0.311556   \n",
       " 141082   213.512766        0.406916       0.061067          0.407063   \n",
       " 19276   -435.237061        0.647540       0.074888          0.694231   \n",
       " 623224   245.904752        0.393124       0.153432          0.378940   \n",
       " 176924  -120.777909        0.641437       0.077627          0.639662   \n",
       " 547968   325.807968        0.071561       0.084275          0.076486   \n",
       " 152581  -409.213118        0.527380       0.075960          0.533431   \n",
       " 412681  -365.650348        0.278525       0.124945          0.263915   \n",
       " 150742   298.564934        0.244008       0.033684          0.265443   \n",
       " 78764    198.626569        0.526536       0.147221          0.489603   \n",
       " 13902   -326.897247        0.247591       0.114001          0.231714   \n",
       " 479091  -288.773485        0.472642       0.078466          0.469445   \n",
       " 232225  -111.007518        0.573893       0.145006          0.614918   \n",
       " 489999  -156.830722        0.498750       0.128085          0.507200   \n",
       " 150752  -120.294208        0.244008       0.033684          0.257630   \n",
       " 19255    -66.577153        0.647540       0.074888          0.579354   \n",
       " 344463   -47.972704        0.557494       0.150728          0.604434   \n",
       " 412679  -135.589512        0.278525       0.124945          0.265057   \n",
       " 25961   -235.866803        0.341894       0.020029          0.360559   \n",
       " \n",
       "         dir_reco_zenith       energy_0  \n",
       " 172910         6.271266  956837.625772  \n",
       " 12884          0.137703  940966.875772  \n",
       " 172898         0.104397  956837.625772  \n",
       " 115367         0.168090  619955.563272  \n",
       " 2505           0.001806  176606.047647  \n",
       " 122420         0.157544  753777.125772  \n",
       " 152579         6.260420  791761.875772  \n",
       " 44842          6.169360  830510.188272  \n",
       " 210814         0.181908  448200.750772  \n",
       " 258792         0.025149  602612.750772  \n",
       " 210790         0.069467  275884.375772  \n",
       " 141094         0.056978  828694.125772  \n",
       " 166758         0.136180  623593.250772  \n",
       " 547535         0.149999  800442.089809  \n",
       " 547964         6.270197  763162.652309  \n",
       " 50618          0.058244  896545.938272  \n",
       " 6889           6.150920  256109.453897  \n",
       " 128351         0.226315  353723.844522  \n",
       " 244686         0.141937  608400.063272  \n",
       " 198148         0.087432  556164.125772  \n",
       " 56849          0.184019  433267.750772  \n",
       " 78775          0.098148  937697.125772  \n",
       " 78769          0.124428  937697.125772  \n",
       " 260779         0.036373  823849.938272  \n",
       " 352530         0.073681  882946.277309  \n",
       " 312205         0.035672  575160.750772  \n",
       " 344459         0.000000  925394.152309  \n",
       " 78772          0.072319  937697.125772  \n",
       " 128364         0.336629  489395.250772  \n",
       " 166757         0.220115  623593.250772  \n",
       " ...                 ...            ...  \n",
       " 13886          6.070462  836423.500772  \n",
       " 152591         0.044348  791761.875772  \n",
       " 13910          0.165374  836423.500772  \n",
       " 141076         0.010753  828694.125772  \n",
       " 402313         5.933075  774447.589809  \n",
       " 213361         0.066538  298046.188272  \n",
       " 310665         0.068499  811980.625772  \n",
       " 547525         0.139968  800442.089809  \n",
       " 141087         0.000548  828694.125772  \n",
       " 402307         6.029034  774447.589809  \n",
       " 12887          0.122682  940966.875772  \n",
       " 402306         6.273931  774447.589809  \n",
       " 141082         0.039756  828694.125772  \n",
       " 19276          6.266247  896600.063272  \n",
       " 623224         0.225141  970229.589809  \n",
       " 176924         0.103846  329805.032022  \n",
       " 547968         0.349907  763162.652309  \n",
       " 152581         0.045613  791761.875772  \n",
       " 412681         0.219805  694838.027309  \n",
       " 150742         0.164993  844047.938272  \n",
       " 78764          0.153315  937697.125772  \n",
       " 13902          0.231606  836423.500772  \n",
       " 479091         0.100387  972560.339809  \n",
       " 232225         0.108192  522564.563272  \n",
       " 489999         0.233289  666433.027309  \n",
       " 150752         0.107119  844047.938272  \n",
       " 19255          6.219096  896600.063272  \n",
       " 344463         0.091142  925394.152309  \n",
       " 412679         0.094518  694838.027309  \n",
       " 25961          0.074475  130540.047647  \n",
       " \n",
       " [756 rows x 333 columns],\n",
       "         charges_0161  charges_0162  charges_0163  charges_0164  charges_0261  \\\n",
       " 78781       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 260241      0.000000           0.0      0.000000           0.0      0.508107   \n",
       " 303695      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 12881       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 303697      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 211370      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 172907      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 210817      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 89258       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 547952      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 104833      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 2117        0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 15767       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 172899      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 98719       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 35098       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 150758      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 283914      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 78765       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 62756       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 152583      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 479087      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 314683      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 172894      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 152598      0.208993           0.0      2.463921           0.0      2.050636   \n",
       " 547963      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 412687      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 50631       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 166754      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 493703      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " ...              ...           ...           ...           ...           ...   \n",
       " 152606      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 309537      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 479079      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 56857       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 623221      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 19273       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 128353      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 260256      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 491410      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 547540      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 2112        0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 210785      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 352529      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 104840      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 547951      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 158571      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 547961      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 211368      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 186816      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 98734       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 152605      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 260232      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 57337       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 98730       0.000000           0.0      0.000000           0.0      0.539914   \n",
       " 410451      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 300690      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 19265       0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 260781      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 166749      0.000000           0.0      0.000000           0.0      0.000000   \n",
       " 141074      0.000000           0.0      0.000000           0.0     10.132520   \n",
       " \n",
       "         charges_0262  charges_0263  charges_0264  charges_0361  charges_0362  \\\n",
       " 78781            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 260241           0.0      0.744779           0.0      1.583157           0.0   \n",
       " 303695           0.0      0.000000           0.0      1.053497           0.0   \n",
       " 12881            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 303697           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 211370           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 172907           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 210817           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 89258            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 547952           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 104833           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 2117             0.0      0.000000           0.0      0.000000           0.0   \n",
       " 15767            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 172899           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 98719            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 35098            0.0      0.000000           0.0      0.301527           0.0   \n",
       " 150758           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 283914           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 78765            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 62756            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 152583           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 479087           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 314683           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 172894           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 152598           0.0      2.033347           0.0      0.000000           0.0   \n",
       " 547963           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 412687           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 50631            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 166754           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 493703           0.0      0.000000           0.0      0.000000           0.0   \n",
       " ...              ...           ...           ...           ...           ...   \n",
       " 152606           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 309537           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 479079           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 56857            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 623221           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 19273            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 128353           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 260256           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 491410           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 547540           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 2112             0.0      0.000000           0.0      0.000000           0.0   \n",
       " 210785           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 352529           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 104840           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 547951           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 158571           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 547961           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 211368           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 186816           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 98734            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 152605           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 260232           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 57337            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 98730            0.0      0.921125           0.0      0.774714           0.0   \n",
       " 410451           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 300690           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 19265            0.0      0.000000           0.0      0.000000           0.0   \n",
       " 260781           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 166749           0.0      0.000000           0.0      0.000000           0.0   \n",
       " 141074           0.0      9.933364           0.0      0.808759           0.0   \n",
       " \n",
       "             ...        composition_0   core_MC_x   core_MC_y  core_reco_x  \\\n",
       " 78781       ...                PPlus  159.720579 -220.743356   139.990954   \n",
       " 260241      ...                PPlus  -62.462220 -380.608427   -46.961757   \n",
       " 303695      ...                PPlus   35.704536 -374.032903    29.160880   \n",
       " 12881       ...                PPlus -396.132833  110.884013  -359.246741   \n",
       " 303697      ...                PPlus -409.435344  -94.309527  -416.139940   \n",
       " 211370      ...                PPlus -252.091828  254.526610  -261.548081   \n",
       " 172907      ...                PPlus  362.366066    8.978395   353.198682   \n",
       " 210817      ...                PPlus   98.279215  -14.671455    95.640577   \n",
       " 89258       ...                PPlus   64.553686   21.582981    79.912045   \n",
       " 547952      ...          Fe56Nucleus -328.499464  -50.013898  -343.044223   \n",
       " 104833      ...                PPlus -164.646782  241.711141  -192.473723   \n",
       " 2117        ...                PPlus  118.686427  -97.041273   125.278739   \n",
       " 15767       ...                PPlus -253.491355  -12.743452  -255.876326   \n",
       " 172899      ...                PPlus -237.531410  139.897331  -229.037093   \n",
       " 98719       ...                PPlus  -92.195641   10.117253   -94.658970   \n",
       " 35098       ...                PPlus  -19.798827 -346.816338    11.075437   \n",
       " 150758      ...                PPlus  146.340855  112.089948   138.405720   \n",
       " 283914      ...                PPlus -289.944725   36.068455  -303.296709   \n",
       " 78765       ...                PPlus -419.988350   72.723569  -394.200950   \n",
       " 62756       ...                PPlus   24.711550  -72.555023    24.046121   \n",
       " 152583      ...                PPlus -310.289596 -108.898529  -310.846490   \n",
       " 479087      ...          Fe56Nucleus -214.222703  222.257269  -201.058783   \n",
       " 314683      ...                PPlus  128.306514   23.370166    98.221197   \n",
       " 172894      ...                PPlus -207.128375    8.614388  -191.343333   \n",
       " 152598      ...                PPlus -197.702215 -400.921674  -207.870288   \n",
       " 547963      ...          Fe56Nucleus  184.163148 -180.906040   223.092998   \n",
       " 412687      ...          Fe56Nucleus  169.066045 -121.020934   161.315539   \n",
       " 50631       ...                PPlus  103.765716 -165.209219    59.321355   \n",
       " 166754      ...                PPlus  129.379221  -88.463872   121.330114   \n",
       " 493703      ...          Fe56Nucleus -296.463585 -298.753113  -278.214741   \n",
       " ...         ...                  ...         ...         ...          ...   \n",
       " 152606      ...                PPlus  111.155212   27.306705    94.030587   \n",
       " 309537      ...                PPlus -242.737832 -300.266938  -242.597663   \n",
       " 479079      ...          Fe56Nucleus -181.944569  147.211830  -194.341605   \n",
       " 56857       ...                PPlus   89.383046  -12.460148    89.611286   \n",
       " 623221      ...          Fe56Nucleus -186.836277  150.933827  -191.578590   \n",
       " 19273       ...                PPlus  113.657266  -59.472620   105.044759   \n",
       " 128353      ...                PPlus    2.328406 -123.353417    22.940184   \n",
       " 260256      ...                PPlus   42.237039  -48.562371    41.115984   \n",
       " 491410      ...          Fe56Nucleus  193.343945  -79.876462   166.146232   \n",
       " 547540      ...          Fe56Nucleus -128.986318 -103.777529  -137.445493   \n",
       " 2112        ...                PPlus  -31.835975 -107.089193    27.829528   \n",
       " 210785      ...                PPlus -317.449769   91.169001  -298.554066   \n",
       " 352529      ...          Fe56Nucleus  144.560440  -42.653164   118.985242   \n",
       " 104840      ...                PPlus  205.319735 -302.093833   223.004692   \n",
       " 547951      ...          Fe56Nucleus  336.879469  -16.690354   278.284333   \n",
       " 158571      ...                PPlus  158.308269  -25.354124   143.529896   \n",
       " 547961      ...          Fe56Nucleus   91.578813 -148.539137    82.809979   \n",
       " 211368      ...                PPlus  100.627853   23.404740    90.028299   \n",
       " 186816      ...                PPlus -118.724982  -43.136331  -120.610778   \n",
       " 98734       ...                PPlus -368.011260 -115.345900  -343.652623   \n",
       " 152605      ...                PPlus  -39.896066  296.728019   -16.567709   \n",
       " 260232      ...                PPlus -130.009128 -174.728029  -146.853395   \n",
       " 57337       ...                PPlus   41.368157  -75.671020    35.028455   \n",
       " 98730       ...                PPlus  -65.089729 -403.803543   -48.928029   \n",
       " 410451      ...          Fe56Nucleus -214.175467  146.219509  -215.245297   \n",
       " 300690      ...                PPlus -294.971366 -266.987617  -290.959549   \n",
       " 19265       ...                PPlus  239.585143 -365.786544   233.632945   \n",
       " 260781      ...                PPlus -376.525235  -40.355925  -380.263668   \n",
       " 166749      ...                PPlus  242.641185 -287.659662   280.585355   \n",
       " 141074      ...                PPlus -135.357993 -421.365542  -122.104984   \n",
       " \n",
       "         core_reco_y  dir_MC_azimuth  dir_MC_zenith  dir_reco_azimuth  \\\n",
       " 78781   -220.723013        0.526536       0.147221          0.561954   \n",
       " 260241  -366.159697        0.576769       0.102156          0.496854   \n",
       " 303695  -347.362127        0.552466       0.046587          0.545026   \n",
       " 12881     70.858997        0.550200       0.154423          0.539183   \n",
       " 303697   -70.129035        0.552466       0.046587          0.525354   \n",
       " 211370   243.455405        0.824808       0.056466          0.799757   \n",
       " 172907   -16.950413        0.284481       0.090934          0.274957   \n",
       " 210817   -25.881867        0.629870       0.136019          0.650832   \n",
       " 89258     27.950369        0.757207       0.007634          0.880341   \n",
       " 547952   -91.208119        0.071561       0.084275          0.093355   \n",
       " 104833   196.083412        0.562843       0.160297          0.552766   \n",
       " 2117     -86.323842        0.861784       0.090178          0.851162   \n",
       " 15767    -10.007596        0.463202       0.102127          0.457436   \n",
       " 172899   126.568688        0.284481       0.090934          0.322366   \n",
       " 98719      6.502515        0.480871       0.112239          0.479113   \n",
       " 35098   -327.622861        0.252727       0.049266          0.205964   \n",
       " 150758   104.223562        0.244008       0.033684          0.249802   \n",
       " 283914    43.997185        0.593058       0.084546          0.608753   \n",
       " 78765     79.582080        0.526536       0.147221          0.497710   \n",
       " 62756    -73.352070        0.440302       0.142056          0.433661   \n",
       " 152583  -115.292911        0.527380       0.075960          0.532278   \n",
       " 479087   224.439059        0.472642       0.078466          0.465134   \n",
       " 314683     9.569785        0.612625       0.067002          0.669376   \n",
       " 172894     1.722190        0.284481       0.090934          0.265480   \n",
       " 152598  -414.271550        0.527380       0.075960          0.487535   \n",
       " 547963  -173.031677        0.071561       0.084275          0.099294   \n",
       " 412687  -139.410770        0.278525       0.124945          0.296098   \n",
       " 50631   -192.196073        0.669990       0.075197          0.718119   \n",
       " 166754   -85.428928        0.717072       0.161655          0.729591   \n",
       " 493703  -325.066245        0.191299       0.072854          0.190299   \n",
       " ...             ...             ...            ...               ...   \n",
       " 152606     3.598884        0.527380       0.075960          0.567477   \n",
       " 309537  -287.368996        0.418108       0.060750          0.419980   \n",
       " 479079   154.563224        0.045489       0.020128          0.047928   \n",
       " 56857    -22.759414        0.272181       0.082175          0.281905   \n",
       " 623221   152.398530        0.393124       0.153432          0.385289   \n",
       " 19273    -54.078465        0.647540       0.074888          0.637828   \n",
       " 128353  -111.883292        0.312548       0.134542          0.258180   \n",
       " 260256   -53.439562        0.576769       0.102156          0.677366   \n",
       " 491410   -75.431081        0.707650       0.074587          0.714752   \n",
       " 547540   -76.708633        0.509197       0.074494          0.494208   \n",
       " 2112     -93.686833        0.861784       0.090178          0.831996   \n",
       " 210785   104.124800        0.238186       0.062210          0.218980   \n",
       " 352529   -41.788641        0.507170       0.075400          0.508091   \n",
       " 104840  -300.702912        0.562843       0.160297          0.563463   \n",
       " 547951   -26.065262        0.071561       0.084275          0.131906   \n",
       " 158571   -31.988851        0.747764       0.111333          0.777500   \n",
       " 547961  -139.676614        0.071561       0.084275          0.143759   \n",
       " 211368    26.970192        0.824808       0.056466          0.828556   \n",
       " 186816   -28.928367        0.283208       0.045425          0.299762   \n",
       " 98734    -98.338152        0.480871       0.112239          0.454186   \n",
       " 152605   280.851912        0.527380       0.075960          0.514254   \n",
       " 260232  -179.077045        0.576769       0.102156          0.537339   \n",
       " 57337    -69.833543        0.528096       0.043558          0.504196   \n",
       " 98730   -386.533643        0.480871       0.112239          0.482160   \n",
       " 410451   162.726806        0.700904       0.075435          0.700315   \n",
       " 300690  -323.320361        0.632303       0.019957          0.625376   \n",
       " 19265   -375.007946        0.647540       0.074888          0.634286   \n",
       " 260781    -6.254166        0.426446       0.095457          0.351793   \n",
       " 166749  -265.548785        0.717072       0.161655          0.744707   \n",
       " 141074  -420.354494        0.406916       0.061067          0.353263   \n",
       " \n",
       "         dir_reco_zenith       energy_0  \n",
       " 78781          0.192722  937697.125772  \n",
       " 260241         0.150074  561455.500772  \n",
       " 303695         0.022877  929692.875772  \n",
       " 12881          0.263520  940966.875772  \n",
       " 303697         0.025028  929692.875772  \n",
       " 211370         6.263510  992399.625772  \n",
       " 172907         0.263763  956837.625772  \n",
       " 210817         0.176018  448200.750772  \n",
       " 89258          0.049892  641560.563272  \n",
       " 547952         0.172218  763162.652309  \n",
       " 104833         0.214576  832891.063272  \n",
       " 2117           0.065740  621802.438272  \n",
       " 15767          0.183149  373852.844522  \n",
       " 172899         0.103238  956837.625772  \n",
       " 98719          0.191544  739353.313272  \n",
       " 35098          5.943724  304832.813272  \n",
       " 150758         0.144911  844047.938272  \n",
       " 283914         0.054350  350745.844522  \n",
       " 78765          0.164639  937697.125772  \n",
       " 62756          0.231874  425922.094522  \n",
       " 152583         0.154124  791761.875772  \n",
       " 479087         0.125071  972560.339809  \n",
       " 314683         0.110369  659401.125772  \n",
       " 172894         0.122272  956837.625772  \n",
       " 152598         0.055766  791761.875772  \n",
       " 547963         6.228798  763162.652309  \n",
       " 412687         0.222332  694838.027309  \n",
       " 50631          0.000696  896545.938272  \n",
       " 166754         0.182632  623593.250772  \n",
       " 493703         6.217409  460700.464809  \n",
       " ...                 ...            ...  \n",
       " 152606         0.109438  791761.875772  \n",
       " 309537         0.049232  719485.625772  \n",
       " 479079         6.152129  524846.839809  \n",
       " 56857          0.109237  433267.750772  \n",
       " 623221         0.127756  970229.589809  \n",
       " 19273          0.102059  896600.063272  \n",
       " 128353         0.111387  353723.844522  \n",
       " 260256         6.254762  561455.500772  \n",
       " 491410         0.102189  934571.402309  \n",
       " 547540         0.058896  800442.089809  \n",
       " 2112           0.092887  621802.438272  \n",
       " 210785         0.086344  275884.375772  \n",
       " 352529         0.100179  882946.277309  \n",
       " 104840         0.179445  832891.063272  \n",
       " 547951         0.589988  763162.652309  \n",
       " 158571         0.127587  883789.500772  \n",
       " 547961         0.319277  763162.652309  \n",
       " 211368         0.070252  992399.625772  \n",
       " 186816         6.234235  617784.250772  \n",
       " 98734          0.057394  739353.313272  \n",
       " 152605         0.057207  791761.875772  \n",
       " 260232         0.083480  561455.500772  \n",
       " 57337          0.085694  455246.719522  \n",
       " 98730          0.087207  739353.313272  \n",
       " 410451         0.065463  896934.777309  \n",
       " 300690         0.063486  600725.875772  \n",
       " 19265          0.027540  896600.063272  \n",
       " 260781         0.237420  823849.938272  \n",
       " 166749         0.123335  623593.250772  \n",
       " 141074         0.012511  828694.125772  \n",
       " \n",
       " [84 rows x 333 columns])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_and_run(filtered, [x for x in filtered.columns if 'charges' in x], 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use events within certain energy range, azimuth/zenith band, and take an even split between proton and iron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = flatten_event_df(data[\n",
    "        (data.loc[:,('energy',0)] < 1000000) &\n",
    "        data.loc[:, ('dir_MC','zenith')].between(0, .17) &\n",
    "        data.loc[:,('dir_MC','azimuth')].between(0,1) &\n",
    "        (data['charges'].max(axis=1) > 6)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_iron = filtered[filtered['composition_0'] == 'Fe56Nucleus']\n",
    "filtered_proton = filtered[filtered['composition_0'] == 'PPlus']\n",
    "min_size = min(filtered_iron.shape[0], filtered_proton.shape[0])\n",
    "filtered = pd.concat((filtered_iron[:min_size], filtered_proton[:min_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 333)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp00_8b1uy\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_task_id': 0, '_model_dir': '/tmp/tmp00_8b1uy', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1270fc5f98>, '_is_chief': True, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_task_type': 'worker', '_session_config': None, '_log_step_count_steps': 100, '_master': '', '_tf_random_seed': None, '_service': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp00_8b1uy/model.ckpt.\n",
      "INFO:tensorflow:loss = 104.899, step = 1\n",
      "INFO:tensorflow:global_step/sec: 32.0015\n",
      "INFO:tensorflow:loss = 6.75452, step = 101 (3.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6156\n",
      "INFO:tensorflow:loss = 3.53882, step = 201 (2.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2971\n",
      "INFO:tensorflow:loss = 0.947022, step = 301 (3.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9249\n",
      "INFO:tensorflow:loss = 0.525717, step = 401 (2.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.0064\n",
      "INFO:tensorflow:loss = 0.426805, step = 501 (2.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7685\n",
      "INFO:tensorflow:loss = 0.331491, step = 601 (2.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1997\n",
      "INFO:tensorflow:loss = 0.119654, step = 701 (2.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1174\n",
      "INFO:tensorflow:loss = 0.263954, step = 801 (2.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.7256\n",
      "INFO:tensorflow:loss = 0.0730146, step = 901 (2.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.2884\n",
      "INFO:tensorflow:loss = 0.0594104, step = 1001 (2.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9676\n",
      "INFO:tensorflow:loss = 0.0383925, step = 1101 (3.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2094\n",
      "INFO:tensorflow:loss = 0.0829234, step = 1201 (3.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.375\n",
      "INFO:tensorflow:loss = 0.0228423, step = 1301 (3.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9039\n",
      "INFO:tensorflow:loss = 0.0261366, step = 1401 (2.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.5856\n",
      "INFO:tensorflow:loss = 0.0520624, step = 1501 (2.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7455\n",
      "INFO:tensorflow:loss = 0.0265909, step = 1601 (2.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5738\n",
      "INFO:tensorflow:loss = 0.0535536, step = 1701 (2.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1014\n",
      "INFO:tensorflow:loss = 0.028784, step = 1801 (2.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.1535\n",
      "INFO:tensorflow:loss = 0.0226145, step = 1901 (2.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.4055\n",
      "INFO:tensorflow:loss = 0.0216254, step = 2001 (2.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.6135\n",
      "INFO:tensorflow:loss = 0.00981289, step = 2101 (2.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.2404\n",
      "INFO:tensorflow:loss = 0.0245606, step = 2201 (2.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7682\n",
      "INFO:tensorflow:loss = 0.0234596, step = 2301 (2.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.3589\n",
      "INFO:tensorflow:loss = 0.0236788, step = 2401 (2.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.2575\n",
      "INFO:tensorflow:loss = 0.00895806, step = 2501 (2.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.2648\n",
      "INFO:tensorflow:loss = 0.0139861, step = 2601 (2.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.0535\n",
      "INFO:tensorflow:loss = 0.0199859, step = 2701 (2.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7311\n",
      "INFO:tensorflow:loss = 0.023498, step = 2801 (2.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.3004\n",
      "INFO:tensorflow:loss = 0.0273222, step = 2901 (2.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8943\n",
      "INFO:tensorflow:loss = 0.0181329, step = 3001 (2.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8909\n",
      "INFO:tensorflow:loss = 0.0276799, step = 3101 (2.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.0704\n",
      "INFO:tensorflow:loss = 0.00939371, step = 3201 (2.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9324\n",
      "INFO:tensorflow:loss = 0.016038, step = 3301 (2.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.348\n",
      "INFO:tensorflow:loss = 0.0131364, step = 3401 (2.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9546\n",
      "INFO:tensorflow:loss = 0.0157752, step = 3501 (2.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.5143\n",
      "INFO:tensorflow:loss = 0.0129711, step = 3601 (2.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4893\n",
      "INFO:tensorflow:loss = 0.00639983, step = 3701 (2.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.649\n",
      "INFO:tensorflow:loss = 0.00608191, step = 3801 (2.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.7838\n",
      "INFO:tensorflow:loss = 0.00553488, step = 3901 (2.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0406\n",
      "INFO:tensorflow:loss = 0.00803703, step = 4001 (2.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.7849\n",
      "INFO:tensorflow:loss = 0.00361339, step = 4101 (2.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9902\n",
      "INFO:tensorflow:loss = 0.00442233, step = 4201 (2.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.4748\n",
      "INFO:tensorflow:loss = 0.00617007, step = 4301 (2.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4414\n",
      "INFO:tensorflow:loss = 0.0108081, step = 4401 (2.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9399\n",
      "INFO:tensorflow:loss = 0.00315633, step = 4501 (3.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0202\n",
      "INFO:tensorflow:loss = 0.0052119, step = 4601 (2.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.2407\n",
      "INFO:tensorflow:loss = 0.0123882, step = 4701 (2.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.802\n",
      "INFO:tensorflow:loss = 0.00701219, step = 4801 (3.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.64\n",
      "INFO:tensorflow:loss = 0.00970579, step = 4901 (2.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.1776\n",
      "INFO:tensorflow:loss = 0.00441751, step = 5001 (2.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5833\n",
      "INFO:tensorflow:loss = 0.00455578, step = 5101 (2.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.125\n",
      "INFO:tensorflow:loss = 0.00423295, step = 5201 (2.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9701\n",
      "INFO:tensorflow:loss = 0.00368514, step = 5301 (2.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.5734\n",
      "INFO:tensorflow:loss = 0.00859748, step = 5401 (2.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.6682\n",
      "INFO:tensorflow:loss = 0.00590959, step = 5501 (2.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.0812\n",
      "INFO:tensorflow:loss = 0.00426633, step = 5601 (2.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3564\n",
      "INFO:tensorflow:loss = 0.00392216, step = 5701 (2.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.0088\n",
      "INFO:tensorflow:loss = 0.0037743, step = 5801 (2.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.2661\n",
      "INFO:tensorflow:loss = 0.0095631, step = 5901 (2.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1824\n",
      "INFO:tensorflow:loss = 0.00775971, step = 6001 (2.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.621\n",
      "INFO:tensorflow:loss = 0.0039261, step = 6101 (2.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6946\n",
      "INFO:tensorflow:loss = 0.00498952, step = 6201 (2.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8744\n",
      "INFO:tensorflow:loss = 0.00235209, step = 6301 (2.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7106\n",
      "INFO:tensorflow:loss = 0.00937549, step = 6401 (2.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2956\n",
      "INFO:tensorflow:loss = 0.00396347, step = 6501 (3.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2015\n",
      "INFO:tensorflow:loss = 0.00561216, step = 6601 (2.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9091\n",
      "INFO:tensorflow:loss = 0.0068985, step = 6701 (2.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.7359\n",
      "INFO:tensorflow:loss = 0.00979456, step = 6801 (2.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.0061\n",
      "INFO:tensorflow:loss = 0.00441779, step = 6901 (2.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.3881\n",
      "INFO:tensorflow:loss = 0.0036687, step = 7001 (2.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.5104\n",
      "INFO:tensorflow:loss = 0.00499624, step = 7101 (2.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.0818\n",
      "INFO:tensorflow:loss = 0.00301606, step = 7201 (2.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1598\n",
      "INFO:tensorflow:loss = 0.00307181, step = 7301 (2.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.1641\n",
      "INFO:tensorflow:loss = 0.00348331, step = 7401 (2.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5496\n",
      "INFO:tensorflow:loss = 0.00344979, step = 7501 (2.895 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 34.0327\n",
      "INFO:tensorflow:loss = 0.00202441, step = 7601 (2.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6921\n",
      "INFO:tensorflow:loss = 0.00238525, step = 7701 (2.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5147\n",
      "INFO:tensorflow:loss = 0.00387498, step = 7801 (2.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3351\n",
      "INFO:tensorflow:loss = 0.00365333, step = 7901 (2.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.1694\n",
      "INFO:tensorflow:loss = 0.00366067, step = 8001 (2.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.8804\n",
      "INFO:tensorflow:loss = 0.00233, step = 8101 (2.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8602\n",
      "INFO:tensorflow:loss = 0.00256682, step = 8201 (2.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.8619\n",
      "INFO:tensorflow:loss = 0.00359726, step = 8301 (3.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9897\n",
      "INFO:tensorflow:loss = 0.00282887, step = 8401 (2.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.1257\n",
      "INFO:tensorflow:loss = 0.00170409, step = 8501 (2.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1318\n",
      "INFO:tensorflow:loss = 0.00203271, step = 8601 (3.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6658\n",
      "INFO:tensorflow:loss = 0.00121706, step = 8701 (2.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2461\n",
      "INFO:tensorflow:loss = 0.00295929, step = 8801 (2.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.2085\n",
      "INFO:tensorflow:loss = 0.00101073, step = 8901 (2.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8447\n",
      "INFO:tensorflow:loss = 0.00276164, step = 9001 (2.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9129\n",
      "INFO:tensorflow:loss = 0.00205318, step = 9101 (2.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.7115\n",
      "INFO:tensorflow:loss = 0.00242508, step = 9201 (2.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.2805\n",
      "INFO:tensorflow:loss = 0.00370256, step = 9301 (2.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2126\n",
      "INFO:tensorflow:loss = 0.00376066, step = 9401 (2.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9418\n",
      "INFO:tensorflow:loss = 0.005741, step = 9501 (2.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.9764\n",
      "INFO:tensorflow:loss = 0.00239593, step = 9601 (2.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8048\n",
      "INFO:tensorflow:loss = 0.00426235, step = 9701 (2.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.7295\n",
      "INFO:tensorflow:loss = 0.00242583, step = 9801 (2.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.2528\n",
      "INFO:tensorflow:loss = 0.00296307, step = 9901 (2.547 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmp00_8b1uy/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00165961.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-14-17:11:33\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp00_8b1uy/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-14-17:11:34\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.55, accuracy_baseline = 0.55, auc = 0.618687, auc_precision_recall = 0.693065, average_loss = 4.8461, global_step = 10000, label/mean = 0.55, loss = 193.844, prediction/mean = 0.355985\n",
      "\n",
      "Test set accuracy: 0.550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = split_and_run(filtered, [x for x in filtered.columns if 'charges' in x], 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give all the metadata (energy, core, direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a sample so we don't break tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_flat = flatten_event_df(data).sample(frac=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpj0xvc5em\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_task_id': 0, '_model_dir': '/tmp/tmpj0xvc5em', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1271a54d30>, '_is_chief': True, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_task_type': 'worker', '_session_config': None, '_log_step_count_steps': 100, '_master': '', '_tf_random_seed': None, '_service': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpj0xvc5em/model.ckpt.\n",
      "INFO:tensorflow:loss = 8.63516e+07, step = 1\n",
      "INFO:tensorflow:global_step/sec: 23.2362\n",
      "INFO:tensorflow:loss = 212813.0, step = 101 (4.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2013\n",
      "INFO:tensorflow:loss = 423686.0, step = 201 (3.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0057\n",
      "INFO:tensorflow:loss = 17347.4, step = 301 (3.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1298\n",
      "INFO:tensorflow:loss = 24226.8, step = 401 (3.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9861\n",
      "INFO:tensorflow:loss = 18435.4, step = 501 (4.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7783\n",
      "INFO:tensorflow:loss = 6450.65, step = 601 (3.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4876\n",
      "INFO:tensorflow:loss = 38030.0, step = 701 (3.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8996\n",
      "INFO:tensorflow:loss = 39713.4, step = 801 (3.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.093\n",
      "INFO:tensorflow:loss = 972.798, step = 901 (3.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3913\n",
      "INFO:tensorflow:loss = 2651.7, step = 1001 (3.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3316\n",
      "INFO:tensorflow:loss = 11511.3, step = 1101 (3.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9308\n",
      "INFO:tensorflow:loss = 12680.0, step = 1201 (3.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1982\n",
      "INFO:tensorflow:loss = 33326.4, step = 1301 (3.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3656\n",
      "INFO:tensorflow:loss = 342.649, step = 1401 (3.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0843\n",
      "INFO:tensorflow:loss = 69.4194, step = 1501 (3.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6336\n",
      "INFO:tensorflow:loss = 67.6868, step = 1601 (3.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6669\n",
      "INFO:tensorflow:loss = 67.064, step = 1701 (3.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9045\n",
      "INFO:tensorflow:loss = 69.8209, step = 1801 (3.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0262\n",
      "INFO:tensorflow:loss = 69.0246, step = 1901 (3.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.656\n",
      "INFO:tensorflow:loss = 71.1153, step = 2001 (3.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4546\n",
      "INFO:tensorflow:loss = 70.2606, step = 2101 (3.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6011\n",
      "INFO:tensorflow:loss = 69.3426, step = 2201 (3.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.667\n",
      "INFO:tensorflow:loss = 69.4741, step = 2301 (3.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.644\n",
      "INFO:tensorflow:loss = 68.3507, step = 2401 (3.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9992\n",
      "INFO:tensorflow:loss = 69.395, step = 2501 (3.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8911\n",
      "INFO:tensorflow:loss = 67.5427, step = 2601 (2.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.0867\n",
      "INFO:tensorflow:loss = 68.7858, step = 2701 (2.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5969\n",
      "INFO:tensorflow:loss = 69.4704, step = 2801 (6.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.8464\n",
      "INFO:tensorflow:loss = 69.0854, step = 2901 (2.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3012\n",
      "INFO:tensorflow:loss = 69.239, step = 3001 (2.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3833\n",
      "INFO:tensorflow:loss = 69.6111, step = 3101 (2.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4693\n",
      "INFO:tensorflow:loss = 68.913, step = 3201 (2.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6614\n",
      "INFO:tensorflow:loss = 69.3318, step = 3301 (2.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7463\n",
      "INFO:tensorflow:loss = 69.6215, step = 3401 (2.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9843\n",
      "INFO:tensorflow:loss = 68.7377, step = 3501 (2.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4799\n",
      "INFO:tensorflow:loss = 68.6571, step = 3601 (3.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4164\n",
      "INFO:tensorflow:loss = 69.1359, step = 3701 (3.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7305\n",
      "INFO:tensorflow:loss = 68.7633, step = 3801 (3.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.8822\n",
      "INFO:tensorflow:loss = 68.4691, step = 3901 (2.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.7772\n",
      "INFO:tensorflow:loss = 69.5859, step = 4001 (2.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9571\n",
      "INFO:tensorflow:loss = 70.2781, step = 4101 (2.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6594\n",
      "INFO:tensorflow:loss = 68.6577, step = 4201 (2.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4571\n",
      "INFO:tensorflow:loss = 72.1713, step = 4301 (2.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6424\n",
      "INFO:tensorflow:loss = 68.7548, step = 4401 (2.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9376\n",
      "INFO:tensorflow:loss = 69.93, step = 4501 (2.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8139\n",
      "INFO:tensorflow:loss = 68.3487, step = 4601 (2.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.3367\n",
      "INFO:tensorflow:loss = 68.7155, step = 4701 (2.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8719\n",
      "INFO:tensorflow:loss = 68.5908, step = 4801 (2.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1917\n",
      "INFO:tensorflow:loss = 69.3574, step = 4901 (2.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9122\n",
      "INFO:tensorflow:loss = 69.2481, step = 5001 (3.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7155\n",
      "INFO:tensorflow:loss = 69.4846, step = 5101 (3.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.513\n",
      "INFO:tensorflow:loss = 69.6078, step = 5201 (3.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9156\n",
      "INFO:tensorflow:loss = 67.9534, step = 5301 (2.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4011\n",
      "INFO:tensorflow:loss = 69.4489, step = 5401 (2.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2767\n",
      "INFO:tensorflow:loss = 70.3063, step = 5501 (2.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4408\n",
      "INFO:tensorflow:loss = 69.1346, step = 5601 (7.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.8086\n",
      "INFO:tensorflow:loss = 69.3544, step = 5701 (2.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5805\n",
      "INFO:tensorflow:loss = 68.094, step = 5801 (3.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.1935\n",
      "INFO:tensorflow:loss = 69.8031, step = 5901 (3.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9469\n",
      "INFO:tensorflow:loss = 68.805, step = 6001 (3.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5353\n",
      "INFO:tensorflow:loss = 69.5841, step = 6101 (3.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.9094\n",
      "INFO:tensorflow:loss = 68.5732, step = 6201 (3.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4018\n",
      "INFO:tensorflow:loss = 68.9669, step = 6301 (3.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2028\n",
      "INFO:tensorflow:loss = 68.3152, step = 6401 (3.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5319\n",
      "INFO:tensorflow:loss = 68.2029, step = 6501 (3.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9287\n",
      "INFO:tensorflow:loss = 69.2438, step = 6601 (3.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0311\n",
      "INFO:tensorflow:loss = 68.7462, step = 6701 (3.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1343\n",
      "INFO:tensorflow:loss = 68.1244, step = 6801 (3.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4269\n",
      "INFO:tensorflow:loss = 69.1401, step = 6901 (2.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8215\n",
      "INFO:tensorflow:loss = 68.4462, step = 7001 (2.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6687\n",
      "INFO:tensorflow:loss = 68.3741, step = 7101 (2.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8522\n",
      "INFO:tensorflow:loss = 69.1372, step = 7201 (2.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0831\n",
      "INFO:tensorflow:loss = 68.6544, step = 7301 (3.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3388\n",
      "INFO:tensorflow:loss = 68.3215, step = 7401 (3.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0946\n",
      "INFO:tensorflow:loss = 69.4496, step = 7501 (2.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0174\n",
      "INFO:tensorflow:loss = 70.0078, step = 7601 (3.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 69.5203, step = 7701 (3.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1727\n",
      "INFO:tensorflow:loss = 69.1352, step = 7801 (3.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9698\n",
      "INFO:tensorflow:loss = 68.7872, step = 7901 (3.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6814\n",
      "INFO:tensorflow:loss = 68.8302, step = 8001 (3.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0316\n",
      "INFO:tensorflow:loss = 70.3417, step = 8101 (2.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6315\n",
      "INFO:tensorflow:loss = 68.6431, step = 8201 (2.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4879\n",
      "INFO:tensorflow:loss = 68.8097, step = 8301 (4.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7464\n",
      "INFO:tensorflow:loss = 68.7516, step = 8401 (6.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9731\n",
      "INFO:tensorflow:loss = 66.6907, step = 8501 (3.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0713\n",
      "INFO:tensorflow:loss = 69.8698, step = 8601 (3.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7968\n",
      "INFO:tensorflow:loss = 69.2358, step = 8701 (3.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4982\n",
      "INFO:tensorflow:loss = 68.7164, step = 8801 (3.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4871\n",
      "INFO:tensorflow:loss = 69.8478, step = 8901 (2.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2622\n",
      "INFO:tensorflow:loss = 68.3713, step = 9001 (3.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5977\n",
      "INFO:tensorflow:loss = 68.9739, step = 9101 (3.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4604\n",
      "INFO:tensorflow:loss = 68.8901, step = 9201 (3.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1069\n",
      "INFO:tensorflow:loss = 68.9305, step = 9301 (3.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8704\n",
      "INFO:tensorflow:loss = 69.2433, step = 9401 (3.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9365\n",
      "INFO:tensorflow:loss = 71.1584, step = 9501 (3.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5858\n",
      "INFO:tensorflow:loss = 69.8696, step = 9601 (3.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0009\n",
      "INFO:tensorflow:loss = 69.09, step = 9701 (3.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3778\n",
      "INFO:tensorflow:loss = 69.136, step = 9801 (3.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.6667\n",
      "INFO:tensorflow:loss = 69.1354, step = 9901 (2.728 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpj0xvc5em/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 70.3014.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-14-17:35:34\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpj0xvc5em/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-14-17:35:44\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.522729, accuracy_baseline = 0.52273, auc = 0.501268, auc_precision_recall = 0.738739, average_loss = 0.691883, global_step = 10000, label/mean = 0.477271, loss = 69.0069, prediction/mean = 0.471273\n",
      "\n",
      "Test set accuracy: 0.523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_and_run(full_flat, ['core_MC_x', 'core_MC_y', 'dir_MC_azimuth', 'dir_MC_zenith', 'energy_0'] + [x for x in filtered.columns if 'charges' in x], 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
